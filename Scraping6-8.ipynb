{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "\n",
    "BASE_URL = \"http://en.wikipedia.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NWinnerItemBio(scrapy.Item):\n",
    "    link = scrapy.Field()\n",
    "    name = scrapy.Field()\n",
    "    mini_bio = scrapy.Field()\n",
    "    image_urls = scrapy.Field()\n",
    "    bio_image = scrapy.Field()\n",
    "    images = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NWinnerSpiderBio(scrapy.Spider):\n",
    "    name = 'nwinners_minibio'\n",
    "    allowed_domains = ['en.wikipedia.org']\n",
    "    start_urls = [\"https://en.wikipedia.org/wiki/List_of_Nobel_laureates_by_country\"]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        filename = response.url.split('/')[-1]\n",
    "        h2s = response.xpath('//h2')\n",
    "        \n",
    "        for h2 in h2s:\n",
    "            country = h2.xpath('span[@class=\"mw-headline\"]text()').extract()\n",
    "            if country:\n",
    "                winners = h2.xpath('following-siblng::ol[1]')\n",
    "                for w in winners.xpath('li'):\n",
    "                    wdata = {}\n",
    "                    wdata['link'] = BASE_URL + w.xpath('a/@href').extract()[0]\n",
    "                    # get_mini_bio メソッドで受賞者の人物情報ページを処理する\n",
    "                    request = scrapy.Request(wdata['link'], callback=self.get_mini_bio)\n",
    "                    request.meta['item'] = NWinnerItem(**wdata)\n",
    "                    yield request\n",
    "                            \n",
    "    def get_mini_bio(self, response):\n",
    "        \"\"\" 受賞者の人物情報テキストと写真を取得する \"\"\"\n",
    "        \n",
    "        BASE_URL_ESCAPED = 'http:\\/\\/en.wikipedia.org'\n",
    "        item = response.meta['item']\n",
    "        item['image_urls'] = []\n",
    "        img_src = responsr.xpath('//table[contains(@class,\"inforbox\")]//img/@src')\n",
    "        if img_src:\n",
    "            item['image_urls'] = ['http' + img_src[0].extract()]\n",
    "        mini_nib = ''\n",
    "        paras = response.xpath('//*[@id=\"mw-content-text\"]/p[text() or normalize-space(.)=\"\"]').extract()\n",
    "        \n",
    "        for p in paras:\n",
    "            if p == '<p></p>':\n",
    "                break\n",
    "            mini_bio += p\n",
    "        \n",
    "        # ウィキリンクの補正\n",
    "        mini_bio = mini_bio.replace('href=\"/wiki', 'href=\"' + BASE_URL + '/wiki')\n",
    "        mini_bio = mini_bio.replace('href=\"#', item['link'] + '#')\n",
    "        item['mini_bio'] = mini_bio\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.pipelines.images import ImagesPipeline\n",
    "from scrapy.exceptions import DropItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NobelImagesPipeline(ImagesPipeline):\n",
    "    \n",
    "    def get_media_requests(self, item, info):\n",
    "        \n",
    "        for image_url in item['images_urls']:\n",
    "            yield scrapy.Request(image_url)\n",
    "    \n",
    "    def item_completed(self, results, item, info):\n",
    "        \n",
    "        image_paths = [x['path'] for ok, x in results if ok]\n",
    "        if image_paths:\n",
    "            item['bio_image'] = image_paths[0]\n",
    "            \n",
    "        return item"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
